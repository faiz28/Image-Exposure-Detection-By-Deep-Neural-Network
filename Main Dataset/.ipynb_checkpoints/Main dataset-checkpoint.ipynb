{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19b9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, Accuracy\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam,schedules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DIR = './Small-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Small_CNN_Classifier.hdf5'\n",
    "\n",
    "print(\"data\")\n",
    "\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "sgd = SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021e4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "TRAIN_SPLIT = 0.85\n",
    "\n",
    "DIR = './'\n",
    "imgH = 32\n",
    "imgW = 32\n",
    "\n",
    "# file = open('data_index.txt', 'w')\n",
    "count = 0\n",
    "\n",
    "def load_image_data():\n",
    "    imgDir = DIR + 'Normal/'\n",
    "    imgSet1 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    m = imgSet1.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'OverExposed/'\n",
    "    imgSet2 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    n = imgSet2.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'UnderExposed/'\n",
    "    imgSet3 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    o = imgSet3.shape[0]\n",
    "\n",
    "    # Put all image data into one array.\n",
    "    imgSet = np.concatenate((imgSet1, imgSet2, imgSet3), axis=0)\n",
    "    print(imgSet.shape)\n",
    "\n",
    "    labelSet1 = np.zeros(m, dtype=np.uint8)\n",
    "    labelSet2 = np.ones(n, dtype=np.uint8)\n",
    "    label_o = np.ones(o, dtype=np.uint8)\n",
    "    labelSet3 = np.add(label_o, label_o)\n",
    "    labelSet = np.concatenate((labelSet1, labelSet2, labelSet3), axis=0)\n",
    "\n",
    "\n",
    "    p = imgSet.shape[0]  # p = n + m + o\n",
    "\n",
    "    # random.shuffle(indices)\n",
    "    # for i in range(len(indices)):\n",
    "    #     file.write(str(indices[i])+\",\")\n",
    "    \n",
    "    # file.close()\n",
    "    f = open('data_index.txt', 'r')\n",
    "    indices = []\n",
    "    for x in f.read().split(','):\n",
    "        if len(x) > 0:\n",
    "            num = ''\n",
    "            for j in x:\n",
    "                if(j>='0' and j<='9'):\n",
    "                    num +=j;\n",
    "            if len(num)>0 and  int(num)<p:\n",
    "                indices.append(int(num)) \n",
    "   \n",
    "    # print(indices)\n",
    "    imgSet = imgSet[indices]\n",
    "    labelSet = labelSet[indices]\n",
    "    print(labelSet[:5])\n",
    "    print(\"Label set : \")\n",
    "    labelSet = labelSet.reshape(p, 1)\n",
    "\n",
    "#   one hot encoding\n",
    "\n",
    "    labelSet = to_categorical(labelSet)\n",
    "\n",
    "    # print(labelSet[:5])\n",
    "    \n",
    "    # print(imgSet[0])\n",
    "    imgSet = imgSet.astype(np.float32)\n",
    "    imgSet = imgSet/255.0\n",
    "\n",
    "    r = int(p * TRAIN_SPLIT)\n",
    "    trainX = imgSet[:r]\n",
    "    trainY = labelSet[:r]\n",
    "    testX = imgSet[r:]\n",
    "    testY = labelSet[r:]\n",
    "\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "\n",
    "def prepare_image_array(imgDir, imgW, imgH):\n",
    "    imgList = os.listdir(imgDir)\n",
    "    # print(imgList)\n",
    "    n = len(imgList)\n",
    "\n",
    "    imgSet = []\n",
    "    for i in range(n):\n",
    "        imgPath = imgDir + imgList[i]\n",
    "        if (os.path.exists(imgPath)):\n",
    "            # print(imgPath)\n",
    "            img = cv2.imread(imgPath)\n",
    "            resizedImg = cv2.resize(img, (imgW, imgH))\n",
    "            rgbImg = cv2.cvtColor(resizedImg, cv2.COLOR_BGR2RGB)\n",
    "            imgSet.append(rgbImg)\n",
    "        else:\n",
    "            print(\"It is not a valid image path.\")\n",
    "\n",
    "    # print(\"total image \"+str(len(imgSet)))\n",
    "    imgSet = np.array(imgSet, dtype=np.uint8)\n",
    "    # print(\"total shape \"+str(imgSet.shape))\n",
    "\n",
    "    return imgSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_Y, testInSet, testOutSet =load_image.load_image_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(modelpath, compile = False)\n",
    "model.compile(loss = 'mse', optimizer = sgd, metrics = ['accuracy', Recall(), Precision()])\n",
    "\n",
    "print(testOutSet[:5])\n",
    "\n",
    "y_test = np.argwhere(testOutSet)[:,1]\n",
    "print(testOutSet)\n",
    "indices = np.argwhere(np.argwhere(y_test) == 0)\n",
    "testInNormal = testInSet[indices]\n",
    "testOutNormal = testOutSet[indices]\n",
    "indices = np.argwhere(y_test == 1)\n",
    "testInOver = testInSet[indices]\n",
    "testOutOver = testOutSet[indices]\n",
    "indices = np.argwhere(y_test == 2)\n",
    "testInUnder = testInSet[indices]\n",
    "testOutUnder = testOutSet[indices]\n",
    "\n",
    "print(indices)\n",
    "\n",
    "'''\tTest Model. '''\n",
    "lossT, accT, precisionT, recallT = model.evaluate(testInSet, testOutSet)\n",
    "lossN, accN, precisionN, recallN = model.evaluate(testInNormal, testOutNormal)\n",
    "lossO, accO, precisionO, recallO = model.evaluate(testInOver, testOutOver)\n",
    "lossU, accU, precisionU, recallU = model.evaluate(testInUnder, testOutUnder)\n",
    "\n",
    "print(\"\\n\\nlossT = %s, accT = %s,  precisionT = %s, recallT = %s \"%(lossT, accT, precisionT, recallT))\n",
    "print(\"lossN = %s, accN = %s,  precisionN = %s, recallN = %s \"%(lossN, accN, precisionN, recallN))\n",
    "print(\"lossO = %s, accO = %s,  precisionO = %s, recallO = %s \"%(lossO, accO, precisionO, recallO))\n",
    "print(\"lossU = %s, accU = %s,  precisionU = %s, recallU = %s \"%(lossU, accU, precisionU, recallU))\n",
    "\n",
    "predicted_output = []\n",
    "prediction = model.predict(testInSet)\n",
    "for i in prediction:\n",
    "    predicted_output.append(np.argmax(i)) \n",
    "\n",
    "actual_output = []\n",
    "for i in testOutSet:\n",
    "    actual_output.append(np.argmax(i)) \n",
    "con_mat = confusion_matrix(actual_output, predicted_output)\n",
    "for i in con_mat:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848d3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
