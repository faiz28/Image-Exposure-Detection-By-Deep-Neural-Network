{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396dc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, Accuracy\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam,schedules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af12a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "TRAIN_SPLIT = 0.85\n",
    "\n",
    "DIR = './'\n",
    "imgH = 32\n",
    "imgW = 32\n",
    "\n",
    "# file = open('data_index.txt', 'w')\n",
    "count = 0\n",
    "\n",
    "def load_image_data():\n",
    "    imgDir = DIR + 'Normal/'\n",
    "    imgSet1 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    m = imgSet1.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'OverExposed/'\n",
    "    imgSet2 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    n = imgSet2.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'UnderExposed/'\n",
    "    imgSet3 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    o = imgSet3.shape[0]\n",
    "\n",
    "    # Put all image data into one array.\n",
    "    imgSet = np.concatenate((imgSet1, imgSet2, imgSet3), axis=0)\n",
    "    print(imgSet.shape)\n",
    "\n",
    "    labelSet1 = np.zeros(m, dtype=np.uint8)\n",
    "    labelSet2 = np.ones(n, dtype=np.uint8)\n",
    "    label_o = np.ones(o, dtype=np.uint8)\n",
    "    labelSet3 = np.add(label_o, label_o)\n",
    "    labelSet = np.concatenate((labelSet1, labelSet2, labelSet3), axis=0)\n",
    "\n",
    "\n",
    "    p = imgSet.shape[0]  # p = n + m + o\n",
    "\n",
    "    # random.shuffle(indices)\n",
    "    # for i in range(len(indices)):\n",
    "    #     file.write(str(indices[i])+\",\")\n",
    "    \n",
    "    # file.close()\n",
    "    f = open('data_index.txt', 'r')\n",
    "    indices = []\n",
    "    for x in f.read().split(','):\n",
    "        if len(x) > 0:\n",
    "            num = ''\n",
    "            for j in x:\n",
    "                if(j>='0' and j<='9'):\n",
    "                    num +=j;\n",
    "            if len(num)>0 and  int(num)<p:\n",
    "                indices.append(int(num)) \n",
    "   \n",
    "    # print(indices)\n",
    "    imgSet = imgSet[indices]\n",
    "    labelSet = labelSet[indices]\n",
    "    print(labelSet[:5])\n",
    "    print(\"Label set : \")\n",
    "    labelSet = labelSet.reshape(p, 1)\n",
    "\n",
    "#   one hot encoding\n",
    "\n",
    "    labelSet = to_categorical(labelSet)\n",
    "\n",
    "    # print(labelSet[:5])\n",
    "    \n",
    "    # print(imgSet[0])\n",
    "    imgSet = imgSet.astype(np.float32)\n",
    "    imgSet = imgSet/255.0\n",
    "\n",
    "    r = int(p * TRAIN_SPLIT)\n",
    "    trainX = imgSet[:r]\n",
    "    trainY = labelSet[:r]\n",
    "    testX = imgSet[r:]\n",
    "    testY = labelSet[r:]\n",
    "\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "\n",
    "def prepare_image_array(imgDir, imgW, imgH):\n",
    "    imgList = os.listdir(imgDir)\n",
    "    # print(imgList)\n",
    "    n = len(imgList)\n",
    "\n",
    "    imgSet = []\n",
    "    for i in range(n):\n",
    "        imgPath = imgDir + imgList[i]\n",
    "        if (os.path.exists(imgPath)):\n",
    "            # print(imgPath)\n",
    "            img = cv2.imread(imgPath)\n",
    "            resizedImg = cv2.resize(img, (imgW, imgH))\n",
    "            rgbImg = cv2.cvtColor(resizedImg, cv2.COLOR_BGR2RGB)\n",
    "            imgSet.append(rgbImg)\n",
    "        else:\n",
    "            print(\"It is not a valid image path.\")\n",
    "\n",
    "    # print(\"total image \"+str(len(imgSet)))\n",
    "    imgSet = np.array(imgSet, dtype=np.uint8)\n",
    "    # print(\"total shape \"+str(imgSet.shape))\n",
    "\n",
    "    return imgSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f48c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8910, 32, 32, 3)\n",
      "[0 2 1 2 0]\n",
      "Label set : \n"
     ]
    }
   ],
   "source": [
    "train_x,train_Y, testInSet, testOutSet =load_image_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c794c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_model(modelpath,testInSet, testOutSet):\n",
    "\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    model = load_model(modelpath, compile = True)\n",
    "    model.compile(loss = 'mse', optimizer = sgd, metrics = ['accuracy', Recall(), Precision()])\n",
    "    \n",
    "\n",
    "\n",
    "#     y_test = np.argwhere(testOutSet)[:,1]\n",
    "    # print(y_test)\n",
    "#     indices = np.argwhere(y_test == 0).flatten()\n",
    "#     print(indices.shape)\n",
    "#     testInNormal = testInSet[indices]\n",
    "#     testOutNormal = testOutSet[indices]\n",
    "\n",
    "\n",
    "\n",
    "#     indices = np.argwhere(y_test == 1).flatten()\n",
    "#     testInOver = testInSet[indices]\n",
    "#     testOutOver = testOutSet[indices]\n",
    "#     indices = np.argwhere(y_test == 2).flatten()\n",
    "#     testInUnder = testInSet[indices]\n",
    "#     testOutUnder = testOutSet[indices]\n",
    "\n",
    "\n",
    "\n",
    "    '''\tTest Model. '''\n",
    "    lossT, accT, precisionT, recallT = model.evaluate(testInSet, testOutSet)\n",
    "#     lossN, accN, precisionN, recallN = model.evaluate(testInNormal, testOutNormal)\n",
    "#     lossO, accO, precisionO, recallO = model.evaluate(testInOver, testOutOver)\n",
    "#     lossU, accU, precisionU, recallU = model.evaluate(testInUnder, testOutUnder)\n",
    "\n",
    "\n",
    "    print(\"\\n\\nlossT = %s, accT = %s,  precisionT = %s, recallT = %s \"%(lossT, accT, precisionT, recallT))\n",
    "#     print(\"lossN = %s, accN = %s,  precisionN = %s, recallN = %s \"%(lossN, accN, precisionN, recallN))\n",
    "#     print(\"lossO = %s, accO = %s,  precisionO = %s, recallO = %s \"%(lossO, accO, precisionO, recallO))\n",
    "#     print(\"lossU = %s, accU = %s,  precisionU = %s, recallU = %s \"%(lossU, accU, precisionU, recallU))\n",
    "\n",
    "    predicted_output = []\n",
    "    prediction = model.predict(testInSet)\n",
    "    for i in prediction:\n",
    "        predicted_output.append(np.argmax(i)) \n",
    "\n",
    "    actual_output = []\n",
    "    for i in testOutSet:\n",
    "        actual_output.append(np.argmax(i)) \n",
    "    con_mat = confusion_matrix(actual_output, predicted_output)\n",
    "#     for i in con_mat:\n",
    "#         print(i)\n",
    "        \n",
    "    cm =  classification_report(actual_output,predicted_output )\n",
    "#     print(cm)\n",
    "    cm = cm.split(\" \")\n",
    "    count = 0\n",
    "    cnt = 0\n",
    "    first_line = \"Normal \"\n",
    "    second_line = \"Over Expsoed \"\n",
    "    third_line = \"Under Expsoed \"\n",
    "    acc = \"Accuracy & \\multicolumn{3}{r}{\"\n",
    "    mac = \"Macro Avg \"\n",
    "    weight = \"Weighted Avg \"\n",
    "    for i in cm:\n",
    "        if len(i)==4:\n",
    "            count = 0\n",
    "            for j in i:\n",
    "                if j=='.':\n",
    "                    count =1\n",
    "            if count ==1:\n",
    "                if(cnt<3):\n",
    "                    first_line +=\" & %s\"%i[2:]\n",
    "                    first_line +='\\%'\n",
    "                if cnt>=3 and cnt<6:\n",
    "                    second_line += \" & %s\"%i[2:]\n",
    "                    second_line +='\\%'\n",
    "                if cnt>=6 and  cnt<9:\n",
    "                    third_line += \" & %s\"%i[2:]\n",
    "                    third_line +='\\%'\n",
    "                if cnt>=9 and cnt<10:\n",
    "                    acc += \" %s\"%i[2:]\n",
    "                    acc +='\\%}'\n",
    "                if cnt>=10 and cnt<13:\n",
    "                    mac +=\" & %s\"%i[2:]\n",
    "                    mac +='\\%'\n",
    "                if cnt>=13 and cnt<16:\n",
    "                    weight += \" & %s\"%i[2:]\n",
    "                    weight +='\\%'\n",
    "                cnt+=1\n",
    "\n",
    "    print(first_line+'\\\\\\\\')\n",
    "    print(second_line+'\\\\\\\\')\n",
    "    print(third_line+'\\\\\\\\\\\\hline')\n",
    "    print(acc+'\\\\\\\\')\n",
    "    print(mac+'\\\\\\\\')\n",
    "    print(weight+'\\\\\\\\\\hline\\hline\\\\thinlines')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "    first_line = \"Normal \"\n",
    "    second_line = \"Over Expsoed \"\n",
    "    third_line = \"Under Expsoed \"\n",
    "\n",
    "    count = 0\n",
    "    for i in con_mat:\n",
    "        if count==0:\n",
    "            first_line+= ' & '+str(i[0])+ ' & '+str(i[1])+  ' & '+str(i[2])\n",
    "        if count==1:\n",
    "            second_line+=  ' & '+str(i[0])+ ' & '+str(i[1])+  ' & '+str(i[2])\n",
    "        if count==2:\n",
    "            third_line+=   ' & '+str(i[0])+ ' & '+str(i[1])+  ' & '+str(i[2])\n",
    "        count+=1\n",
    "\n",
    "\n",
    "    print(first_line+\" \\\\\\\\\\hline\")\n",
    "    print(second_line+\" \\\\\\\\\\hline\")\n",
    "    print(third_line+\" \\\\\\\\\\hline\")\n",
    "\n",
    "    \n",
    "    return cm,con_mat\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4368d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non trainable\n",
      "42/42 [==============================] - 4s 75ms/step - loss: 0.2214 - accuracy: 0.4383 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "\n",
      "\n",
      "lossT = 0.22138726711273193, accT = 0.4382946789264679,  precisionT = 0.0, recallT = 0.0 \n",
      "Normal  & 37\\% & 53\\% & 43\\%\\\\\n",
      "Over Expsoed  & 60\\% & 16\\% & 25\\%\\\\\n",
      "Under Expsoed  & 48\\% & 62\\% & 54\\%\\\\\\hline\n",
      "Accuracy & \\multicolumn{3}{r}{ 44\\%}\\\\\n",
      "Macro Avg  & 48\\% & 44\\% & 41\\%\\\\\n",
      "Weighted Avg  & 49\\% & 44\\% & 41\\%\\\\\\hline\\hline\\thinlines\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Normal  & 222 & 28 & 167 \\\\\\hline\n",
      "Over Expsoed  & 224 & 70 & 154 \\\\\\hline\n",
      "Under Expsoed  & 160 & 18 & 294 \\\\\\hline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'precision',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'recall',\n",
       "  '',\n",
       "  'f1-score',\n",
       "  '',\n",
       "  '',\n",
       "  'support\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.37',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.53',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.43',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '417\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.60',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.16',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.25',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '448\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '2',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.48',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.62',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.54',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '472\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'accuracy',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.44',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n',\n",
       "  '',\n",
       "  '',\n",
       "  'macro',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.48',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.44',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.41',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\nweighted',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.49',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.44',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.41',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n'],\n",
       " array([[222,  28, 167],\n",
       "        [224,  70, 154],\n",
       "        [160,  18, 294]], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Non trainable\")\n",
    "DIR = './non-trainable/'\n",
    "modelpath = DIR + 'VGG_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "121099dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable\n",
      "42/42 [==============================] - 3s 72ms/step - loss: 0.1318 - accuracy: 0.7315 - recall_6: 0.6709 - precision_6: 0.7667\n",
      "\n",
      "\n",
      "lossT = 0.13180872797966003, accT = 0.7314884066581726,  precisionT = 0.6709049940109253, recallT = 0.7666666507720947 \n",
      "Normal  & 61\\% & 54\\% & 57\\%\\\\\n",
      "Over Expsoed  & 78\\% & 76\\% & 77\\%\\\\\n",
      "Under Expsoed  & 78\\% & 87\\% & 82\\%\\\\\\hline\n",
      "Accuracy & \\multicolumn{3}{r}{ 73\\%}\\\\\n",
      "Macro Avg  & 72\\% & 72\\% & 72\\%\\\\\n",
      "Weighted Avg  & 73\\% & 73\\% & 73\\%\\\\\\hline\\hline\\thinlines\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Normal  & 226 & 92 & 99 \\\\\\hline\n",
      "Over Expsoed  & 89 & 340 & 19 \\\\\\hline\n",
      "Under Expsoed  & 56 & 4 & 412 \\\\\\hline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'precision',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'recall',\n",
       "  '',\n",
       "  'f1-score',\n",
       "  '',\n",
       "  '',\n",
       "  'support\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.61',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.54',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.57',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '417\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.78',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.76',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.77',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '448\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '2',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.78',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.87',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.82',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '472\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'accuracy',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.73',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n',\n",
       "  '',\n",
       "  '',\n",
       "  'macro',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.72',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.72',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.72',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\nweighted',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.73',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.73',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.73',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n'],\n",
       " array([[226,  92,  99],\n",
       "        [ 89, 340,  19],\n",
       "        [ 56,   4, 412]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"trainable\")\n",
    "DIR = './trainable/'\n",
    "modelpath = DIR + 'trainable-tf-Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d439c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully connected \n",
      "42/42 [==============================] - 1s 4ms/step - loss: 0.1508 - accuracy: 0.6806 - recall_7: 0.6799 - precision_7: 0.6814\n",
      "\n",
      "\n",
      "lossT = 0.15081512928009033, accT = 0.6806282997131348,  precisionT = 0.6798803210258484, recallT = 0.6814092993736267 \n",
      "Normal  & 52\\% & 65\\% & 57\\%\\\\\n",
      "Over Expsoed  & 89\\% & 46\\% & 61\\%\\\\\n",
      "Under Expsoed  & 75\\% & 92\\% & 82\\%\\\\\\hline\n",
      "Accuracy & \\multicolumn{3}{r}{ 68\\%}\\\\\n",
      "Macro Avg  & 72\\% & 68\\% & 67\\%\\\\\n",
      "Weighted Avg  & 72\\% & 68\\% & 67\\%\\\\\\hline\\hline\\thinlines\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Normal  & 269 & 24 & 124 \\\\\\hline\n",
      "Over Expsoed  & 216 & 208 & 24 \\\\\\hline\n",
      "Under Expsoed  & 36 & 3 & 433 \\\\\\hline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'precision',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'recall',\n",
       "  '',\n",
       "  'f1-score',\n",
       "  '',\n",
       "  '',\n",
       "  'support\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.52',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.65',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.57',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '417\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.89',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.46',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.61',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '448\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '2',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.75',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.92',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.82',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '472\\n\\n',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'accuracy',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.68',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n',\n",
       "  '',\n",
       "  '',\n",
       "  'macro',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.72',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.68',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.67',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\nweighted',\n",
       "  'avg',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.72',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.68',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '0.67',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '1337\\n'],\n",
       " array([[269,  24, 124],\n",
       "        [216, 208,  24],\n",
       "        [ 36,   3, 433]], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"fully connected \")\n",
    "DIR = './Fully-Connnected-model/'\n",
    "modelpath = DIR + 'Fully_connected_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "142b891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smalll\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.7300 - recall_8: 0.7173 - precision_8: 0.7377\n",
      "\n",
      "\n",
      "lossT = 0.12199132144451141, accT = 0.7299925088882446,  precisionT = 0.717277467250824, recallT = 0.7376922965049744 \n",
      "Normal  & 59\\% & 58\\% & 58\\%\\\\\n",
      "Over Expsoed  & 80\\% & 77\\% & 79\\%\\\\\n",
      "Under Expsoed  & 79\\% & 82\\% & 81\\%\\\\\\hline\n",
      "Accuracy & \\multicolumn{3}{r}{ 73\\%}\\\\\n",
      "Macro Avg  & 72\\% & 72\\% & 72\\%\\\\\n",
      "Weighted Avg  & 73\\% & 73\\% & 73\\%\\\\\\hline\\hline\\thinlines\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Normal  & 241 & 83 & 93 \\\\\\hline\n",
      "Over Expsoed  & 90 & 346 & 12 \\\\\\hline\n",
      "Under Expsoed  & 80 & 3 & 389 \\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "print(\"smalll\")\n",
    "DIR = './Small-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Small_CNN_Classifier.hdf5'\n",
    "\n",
    "cm,con_mat = run_model(modelpath,testInSet, testOutSet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec33bba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large-Size-Convolution-Maxpooling-model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(None, 32, 32, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Large-Size-Convolution-Maxpooling-model/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLarge_CNN_Classifier.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestInSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestOutSet\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(modelpath, testInSet, testOutSet)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     y_test = np.argwhere(testOutSet)[:,1]\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# print(y_test)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     indices = np.argwhere(y_test == 0).flatten()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     testInUnder = testInSet[indices]\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#     testOutUnder = testOutSet[indices]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124;03m'''\tTest Model. '''\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     lossT, accT, precisionT, recallT \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestOutSet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#     lossN, accN, precisionN, recallN = model.evaluate(testInNormal, testOutNormal)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#     lossO, accO, precisionO, recallO = model.evaluate(testInOver, testOutOver)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#     lossU, accU, precisionU, recallU = model.evaluate(testInUnder, testOutUnder)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mlossT = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, accT = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m,  precisionT = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, recallT = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(lossT, accT, precisionT, recallT))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\pc5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(None, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Large-Size-Convolution-Maxpooling-model\")\n",
    "DIR = './Large-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Large_CNN_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571b2c5",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2f061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Large-Size-Convolution-Maxpooling-model\")\n",
    "DIR = './Large-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Large_CNN_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)a  = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
