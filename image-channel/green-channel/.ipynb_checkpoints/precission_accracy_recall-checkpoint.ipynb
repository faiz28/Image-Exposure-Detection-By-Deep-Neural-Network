{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396dc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, Accuracy\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam,schedules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af12a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "TRAIN_SPLIT = 0.85\n",
    "\n",
    "DIR = './'\n",
    "imgH = 32\n",
    "imgW = 32\n",
    "\n",
    "# file = open('data_index.txt', 'w')\n",
    "count = 0\n",
    "\n",
    "def load_image_data():\n",
    "    imgDir = DIR + 'Normal/'\n",
    "    imgSet1 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    m = imgSet1.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'OverExposed/'\n",
    "    imgSet2 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    n = imgSet2.shape[0]\n",
    "\n",
    "    imgDir = DIR + 'UnderExposed/'\n",
    "    imgSet3 = prepare_image_array(imgDir, imgW, imgH)\n",
    "    o = imgSet3.shape[0]\n",
    "\n",
    "    # Put all image data into one array.\n",
    "    imgSet = np.concatenate((imgSet1, imgSet2, imgSet3), axis=0)\n",
    "    print(imgSet.shape)\n",
    "\n",
    "    labelSet1 = np.zeros(m, dtype=np.uint8)\n",
    "    labelSet2 = np.ones(n, dtype=np.uint8)\n",
    "    label_o = np.ones(o, dtype=np.uint8)\n",
    "    labelSet3 = np.add(label_o, label_o)\n",
    "    labelSet = np.concatenate((labelSet1, labelSet2, labelSet3), axis=0)\n",
    "\n",
    "\n",
    "    p = imgSet.shape[0]  # p = n + m + o\n",
    "\n",
    "    # random.shuffle(indices)\n",
    "    # for i in range(len(indices)):\n",
    "    #     file.write(str(indices[i])+\",\")\n",
    "    \n",
    "    # file.close()\n",
    "    f = open('data_index.txt', 'r')\n",
    "    indices = []\n",
    "    for x in f.read().split(','):\n",
    "        if len(x) > 0:\n",
    "            num = ''\n",
    "            for j in x:\n",
    "                if(j>='0' and j<='9'):\n",
    "                    num +=j;\n",
    "            if len(num)>0 and  int(num)<p:\n",
    "                indices.append(int(num)) \n",
    "   \n",
    "    # print(indices)\n",
    "    imgSet = imgSet[indices]\n",
    "    labelSet = labelSet[indices]\n",
    "    print(labelSet[:5])\n",
    "    print(\"Label set : \")\n",
    "    labelSet = labelSet.reshape(p, 1)\n",
    "\n",
    "#   one hot encoding\n",
    "\n",
    "    labelSet = to_categorical(labelSet)\n",
    "\n",
    "    # print(labelSet[:5])\n",
    "    \n",
    "    # print(imgSet[0])\n",
    "    imgSet = imgSet.astype(np.float32)\n",
    "    imgSet = imgSet/255.0\n",
    "\n",
    "    r = int(p * TRAIN_SPLIT)\n",
    "    trainX = imgSet[:r]\n",
    "    trainY = labelSet[:r]\n",
    "    testX = imgSet[r:]\n",
    "    testY = labelSet[r:]\n",
    "\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "\n",
    "def prepare_image_array(imgDir, imgW, imgH):\n",
    "    imgList = os.listdir(imgDir)\n",
    "    # print(imgList)\n",
    "    n = len(imgList)\n",
    "\n",
    "    imgSet = []\n",
    "    for i in range(n):\n",
    "        imgPath = imgDir + imgList[i]\n",
    "        if (os.path.exists(imgPath)):\n",
    "            # print(imgPath)\n",
    "            img = cv2.imread(imgPath)\n",
    "            resizedImg = cv2.resize(img, (imgW, imgH))\n",
    "            rgbImg = cv2.cvtColor(resizedImg, cv2.COLOR_BGR2RGB)\n",
    "            imgSet.append(rgbImg)\n",
    "        else:\n",
    "            print(\"It is not a valid image path.\")\n",
    "\n",
    "    # print(\"total image \"+str(len(imgSet)))\n",
    "    imgSet = np.array(imgSet, dtype=np.uint8)\n",
    "    # print(\"total shape \"+str(imgSet.shape))\n",
    "\n",
    "    return imgSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_Y, testInSet, testOutSet =load_image_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c794c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_model(modelpath,testInSet, testOutSet):\n",
    "\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    model = load_model(modelpath, compile = True)\n",
    "    model.compile(loss = 'mse', optimizer = sgd, metrics = ['accuracy', Recall(), Precision()])\n",
    "    \n",
    "\n",
    "\n",
    "#     y_test = np.argwhere(testOutSet)[:,1]\n",
    "    # print(y_test)\n",
    "#     indices = np.argwhere(y_test == 0).flatten()\n",
    "#     print(indices.shape)\n",
    "#     testInNormal = testInSet[indices]\n",
    "#     testOutNormal = testOutSet[indices]\n",
    "\n",
    "\n",
    "\n",
    "#     indices = np.argwhere(y_test == 1).flatten()\n",
    "#     testInOver = testInSet[indices]\n",
    "#     testOutOver = testOutSet[indices]\n",
    "#     indices = np.argwhere(y_test == 2).flatten()\n",
    "#     testInUnder = testInSet[indices]\n",
    "#     testOutUnder = testOutSet[indices]\n",
    "\n",
    "\n",
    "\n",
    "    '''\tTest Model. '''\n",
    "    lossT, accT, precisionT, recallT = model.evaluate(testInSet, testOutSet)\n",
    "#     lossN, accN, precisionN, recallN = model.evaluate(testInNormal, testOutNormal)\n",
    "#     lossO, accO, precisionO, recallO = model.evaluate(testInOver, testOutOver)\n",
    "#     lossU, accU, precisionU, recallU = model.evaluate(testInUnder, testOutUnder)\n",
    "\n",
    "\n",
    "    print(\"\\n\\nlossT = %s, accT = %s,  precisionT = %s, recallT = %s \"%(lossT, accT, precisionT, recallT))\n",
    "#     print(\"lossN = %s, accN = %s,  precisionN = %s, recallN = %s \"%(lossN, accN, precisionN, recallN))\n",
    "#     print(\"lossO = %s, accO = %s,  precisionO = %s, recallO = %s \"%(lossO, accO, precisionO, recallO))\n",
    "#     print(\"lossU = %s, accU = %s,  precisionU = %s, recallU = %s \"%(lossU, accU, precisionU, recallU))\n",
    "\n",
    "    predicted_output = []\n",
    "    prediction = model.predict(testInSet)\n",
    "    for i in prediction:\n",
    "        predicted_output.append(np.argmax(i)) \n",
    "\n",
    "    actual_output = []\n",
    "    for i in testOutSet:\n",
    "        actual_output.append(np.argmax(i)) \n",
    "    con_mat = confusion_matrix(actual_output, predicted_output)\n",
    "    for i in con_mat:\n",
    "        print(i)\n",
    "        \n",
    "    cm =  classification_report(actual_output,predicted_output )\n",
    "    print(cm)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non trainable\")\n",
    "DIR = './non-trainable/'\n",
    "modelpath = DIR + 'VGG_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121099dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testInSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./trainable/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainable-tf-Classifier.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m run_model(modelpath,\u001b[43mtestInSet\u001b[49m, testOutSet)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testInSet' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"trainable\")\n",
    "DIR = './trainable/'\n",
    "modelpath = DIR + 'trainable-tf-Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d439c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully connected \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Fully-Connnected-model/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFully_connected_Classifier.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mrun_model\u001b[49m(modelpath,testInSet, testOutSet)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"fully connected \")\n",
    "DIR = './Fully-Connnected-model/'\n",
    "modelpath = DIR + 'Fully_connected_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "142b891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smalll\n",
      "43/43 [==============================] - 1s 11ms/step - loss: 0.1054 - accuracy: 0.7834 - recall_68: 0.7678 - precision_68: 0.7865\n",
      "\n",
      "\n",
      "lossT = 0.10542751103639603, accT = 0.783382773399353,  precisionT = 0.7678041458129883, recallT = 0.7864741683006287 \n",
      "[288  67  66]\n",
      "[ 75 361  16]\n",
      "[ 67   1 407]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68       421\n",
      "           1       0.84      0.80      0.82       452\n",
      "           2       0.83      0.86      0.84       475\n",
      "\n",
      "    accuracy                           0.78      1348\n",
      "   macro avg       0.78      0.78      0.78      1348\n",
      "weighted avg       0.78      0.78      0.78      1348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"smalll\")\n",
    "DIR = './Small-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Small_CNN_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec33bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large-Size-Convolution-Maxpooling-model\n",
      "43/43 [==============================] - 3s 57ms/step - loss: 0.1594 - accuracy: 0.7211 - recall_69: 0.3909 - precision_69: 0.9039\n",
      "\n",
      "\n",
      "lossT = 0.15939196944236755, accT = 0.721068263053894,  precisionT = 0.390949547290802, recallT = 0.9039450883865356 \n",
      "[144 184  93]\n",
      "[ 31 405  16]\n",
      "[ 43   9 423]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.34      0.45       421\n",
      "           1       0.68      0.90      0.77       452\n",
      "           2       0.80      0.89      0.84       475\n",
      "\n",
      "    accuracy                           0.72      1348\n",
      "   macro avg       0.71      0.71      0.69      1348\n",
      "weighted avg       0.71      0.72      0.70      1348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Large-Size-Convolution-Maxpooling-model\")\n",
    "DIR = './Large-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Large_CNN_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4689035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2f061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Large-Size-Convolution-Maxpooling-model\")\n",
    "DIR = './Large-Size-Convolution-Maxpooling-model/'\n",
    "modelpath = DIR + 'Large_CNN_Classifier.hdf5'\n",
    "run_model(modelpath,testInSet, testOutSet)a  = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
