{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether a simple NN having one neuron can learn a linear function, e.g., y = ax + b. \n",
    "# Sangeeta Biswas\n",
    "# 31.12.2021\n",
    "#\t\n",
    "# How to run:\n",
    "# $ Python_Path ProgramFile_Path\n",
    "# $ Tensorflow/bin/python DeepLearning/1D_LinearFunction_Learner.py\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR = '/home/bibrity/DeepLearning/'\n",
    "\n",
    "def main():\n",
    "\t# Build a model\n",
    "\tmodel = build_model()\n",
    "\t\n",
    "    # Prepare data sets\n",
    "\ttestX, testY, trainX, trainY = prepare_datasets()\n",
    "\t\n",
    "\t# Train the model\n",
    "\tcallbackList = [EarlyStopping(monitor = 'val_loss', patience = 20), History()]\n",
    "\thistory = model.fit(trainX, trainY, epochs = 300, batch_size = 32, callbacks = callbackList, validation_split = 0.2)\n",
    "\tplot_loss(history)\n",
    "\n",
    "\t# Test the performance\n",
    "\tpredictedY = model.predict(testX)\n",
    "\tprint(testY)\n",
    "\tprint(predictedY)\n",
    "\t\n",
    "\tpredictedA = model.layers[1].get_weights()[0][0][0]\n",
    "\tpredictedB = model.layers[1].get_weights()[1][0]\n",
    "\tprint('a: {}, b: {}'.format(predictedA, predictedB))\n",
    "\n",
    "def prepare_datasets():\n",
    "\ttestX = np.arange(100)\n",
    "\ttestY = hidden_function(testX)\n",
    "\ttrainX = np.arange(100, 65000)\n",
    "\ttrainY = hidden_function(trainX)\n",
    "\t\n",
    "\treturn testX, testY, trainX, trainY\n",
    "\t\n",
    "def plot_loss(history):\n",
    "\tloss = history.history['loss']\n",
    "\tvalLoss = history.history['val_loss']\n",
    "\tepochs = range(1, len(loss) + 1)\n",
    "\n",
    "\tplt.figure(figsize = (20, 20))\n",
    "\tplt.rcParams['font.size'] = '20'\n",
    "\tplt.plot(epochs, loss, 'bo-', label = 'Training loss')\n",
    "\tplt.plot(epochs, valLoss, 'k*-', label = 'Validation loss')\n",
    "\tplt.title('Training Loss Vs. Validation Loss')\n",
    "\tplt.legend()\n",
    "\t\n",
    "\tfigPath = DIR + 'TrainvsVal_Loss.png'\n",
    "\tplt.savefig(figPath)\n",
    "\tplt.close()\n",
    "\n",
    "def hidden_function(x):\n",
    "\ta = 5; b = 3\n",
    "\ty = a * x + b\n",
    "\t\n",
    "\treturn y\n",
    "\t\n",
    "def build_model():\n",
    "\t# Layers of the model. \n",
    "\tinputs = Input(1,)\n",
    "\toutputs = Dense(1)(inputs)\n",
    "\n",
    "\t# Build the model. \n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t\n",
    "\t# Configures the model for training. \n",
    "\tmodel.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "\t\n",
    "\t# Display the model architecture.\n",
    "\tmodel.summary() \n",
    "\t\n",
    "\treturn model\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
